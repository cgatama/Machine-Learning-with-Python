{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Pyolite",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "<p style=\"text-align:center\">\n\n</p>\n\n<h1 align=\"center\"><font size=\"5\">Classification with Python</font></h1>\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "<h2>Table of Contents</h2>\n<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n    <ul>\n    <li><a href=\"https://#Section_5\">Instructions</a></li>\n    <li><a href=\"https://#Section_1\">Importing Data </a></li>\n    <li><a href=\"https://#Section_2\">Data Preprocessing</a> </li>\n    <li><a href=\"https://#Section_3\">One Hot Encoding </a></li>\n    <li><a href=\"https://#Section_4\">Train and Test Data Split </a></li>\n    <li><a href=\"https://#Section_6\">Train Logistic Regression, KNN, Decision Tree, SVM, and Linear Regression models and return their appropriate accuracy scores</a></li>\n</a></li>\n</div>\n<p>Estimated Time Needed: <strong>180 min</strong></p>\n</div>\n\n<hr>\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "In this notebook, try to practice all the classification algorithms that we learned in this course.\n\nLoad a dataset using Pandas library, apply the above mentioned algorithms, and find the best model for this specific dataset based on the accuracy evaluation methods.\n\nLet's first install and load all required libraries.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#you are running the lab in your  browser, so we will install the libraries using ``piplite``\nimport piplite\nawait piplite.install(['pandas'])\nawait piplite.install(['numpy'])\n",
      "metadata": {
        "trusted": true
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "# Surpress warnings:\n\ndef warn(\\*args, \\*\\*kwargs):\npass\nimport warnings\nwarnings.warn = warn\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import pandas as pd\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn import preprocessing\nimport numpy as np\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn import svm\nfrom sklearn.metrics import jaccard_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import log_loss\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nimport sklearn.metrics as metrics",
      "metadata": {
        "trusted": true
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "### Data\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "#### About the Data\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "The original source of the data is Australian Government's Bureau of Meteorology and the latest data can be gathered from [http://www.bom.gov.au/climate/dwo/](http://www.bom.gov.au/climate/dwo/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkML0101ENSkillsNetwork20718538-2022-01-01).\n\nThe dataset to be used has extra columns like 'RainToday' and our target is 'RainTomorrow', which was gathered from the Rattle at [https://bitbucket.org/kayontoga/rattle/src/master/data/weatherAUS.RData](https://bitbucket.org/kayontoga/rattle/src/master/data/weatherAUS.RData?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkML0101ENSkillsNetwork20718538-2022-01-01)\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "This dataset contains observations of weather metrics for each day from 2008 to 2017. The **weatherAUS.csv** dataset includes the following fields:\n\n| Field         | Description                                           | Unit            | Type   |\n| ------------- | ----------------------------------------------------- | --------------- | ------ |\n| Date          | Date of the Observation in YYYY-MM-DD                 | Date            | object |\n| Location      | Location of the Observation                           | Location        | object |\n| MinTemp       | Minimum temperature                                   | Celsius         | float  |\n| MaxTemp       | Maximum temperature                                   | Celsius         | float  |\n| Rainfall      | Amount of rainfall                                    | Millimeters     | float  |\n| Evaporation   | Amount of evaporation                                 | Millimeters     | float  |\n| Sunshine      | Amount of bright sunshine                             | hours           | float  |\n| WindGustDir   | Direction of the strongest gust                       | Compass Points  | object |\n| WindGustSpeed | Speed of the strongest gust                           | Kilometers/Hour | object |\n| WindDir9am    | Wind direction averaged of 10 minutes prior to 9am    | Compass Points  | object |\n| WindDir3pm    | Wind direction averaged of 10 minutes prior to 3pm    | Compass Points  | object |\n| WindSpeed9am  | Wind speed averaged of 10 minutes prior to 9am        | Kilometers/Hour | float  |\n| WindSpeed3pm  | Wind speed averaged of 10 minutes prior to 3pm        | Kilometers/Hour | float  |\n| Humidity9am   | Humidity at 9am                                       | Percent         | float  |\n| Humidity3pm   | Humidity at 3pm                                       | Percent         | float  |\n| Pressure9am   | Atmospheric pressure reduced to mean sea level at 9am | Hectopascal     | float  |\n| Pressure3pm   | Atmospheric pressure reduced to mean sea level at 3pm | Hectopascal     | float  |\n| Cloud9am      | Fraction of the sky obscured by cloud at 9am          | Eights          | float  |\n| Cloud3pm      | Fraction of the sky obscured by cloud at 3pm          | Eights          | float  |\n| Temp9am       | Temperature at 9am                                    | Celsius         | float  |\n| Temp3pm       | Temperature at 3pm                                    | Celsius         | float  |\n| RainToday     | If there was rain today                               | Yes/No          | object |\n| RISK_MM       | Amount of rain tomorrow                               | Millimeters     | float  |\n| RainTomorrow  | If there is rain tomorrow                             | Yes/No          | float  |\n\nColumn definitions were gathered from [http://www.bom.gov.au/climate/dwo/IDCJDW0000.shtml](http://www.bom.gov.au/climate/dwo/IDCJDW0000.shtml?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkML0101ENSkillsNetwork20718538-2022-01-01)\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### Instructions\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Below, is where we are going to use the classification algorithms to create a model based on our training data and evaluate our testing data using evaluation metrics learned in the course.\n\nWe will use some of the algorithms taught in the course, specifically:\n\n1.  Logistic Regression\n2.  KNN\n3.  SVM\n4.  Decision Trees\n5.  Linear Regression\n\nWe will evaluate our models using:\n\n1.  Accuracy Score\n2.  Jaccard Index\n3.  F1-Score\n4.  LogLoss\n5.  Mean Absolute Error\n6.  Mean Squared Error\n7.  R2-Score\n\nFinally, you will use your models to generate the report at the end.\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### Importing the Dataset\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from pyodide.http import pyfetch\n\nasync def download(url, filename):\n    response = await pyfetch(url)\n    if response.status == 200:\n        with open(filename, \"wb\") as f:\n            f.write(await response.bytes())",
      "metadata": {
        "trusted": true
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "path='https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-ML0101EN-SkillUp/labs/ML-FinalAssignment/Weather_Data.csv'",
      "metadata": {
        "trusted": true
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "await download(path, \"Weather_Data.csv\")\nfilename =\"Weather_Data.csv\"",
      "metadata": {
        "trusted": true
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "df = pd.read_csv(\"Weather_Data.csv\")\ndf.head()",
      "metadata": {
        "trusted": true
      },
      "execution_count": 6,
      "outputs": [
        {
          "execution_count": 6,
          "output_type": "execute_result",
          "data": {
            "text/plain": "       Date  MinTemp  MaxTemp  Rainfall  Evaporation  Sunshine WindGustDir  \\\n0  2/1/2008     19.5     22.4      15.6          6.2       0.0           W   \n1  2/2/2008     19.5     25.6       6.0          3.4       2.7           W   \n2  2/3/2008     21.6     24.5       6.6          2.4       0.1           W   \n3  2/4/2008     20.2     22.8      18.8          2.2       0.0           W   \n4  2/5/2008     19.7     25.7      77.4          4.8       0.0           W   \n\n   WindGustSpeed WindDir9am WindDir3pm  ...  Humidity9am  Humidity3pm  \\\n0             41          S        SSW  ...           92           84   \n1             41          W          E  ...           83           73   \n2             41        ESE        ESE  ...           88           86   \n3             41        NNE          E  ...           83           90   \n4             41        NNE          W  ...           88           74   \n\n   Pressure9am  Pressure3pm  Cloud9am  Cloud3pm  Temp9am  Temp3pm  RainToday  \\\n0       1017.6       1017.4         8         8     20.7     20.9        Yes   \n1       1017.9       1016.4         7         7     22.4     24.8        Yes   \n2       1016.7       1015.6         7         8     23.5     23.0        Yes   \n3       1014.2       1011.8         8         8     21.4     20.9        Yes   \n4       1008.3       1004.8         8         8     22.5     25.5        Yes   \n\n   RainTomorrow  \n0           Yes  \n1           Yes  \n2           Yes  \n3           Yes  \n4           Yes  \n\n[5 rows x 22 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date</th>\n      <th>MinTemp</th>\n      <th>MaxTemp</th>\n      <th>Rainfall</th>\n      <th>Evaporation</th>\n      <th>Sunshine</th>\n      <th>WindGustDir</th>\n      <th>WindGustSpeed</th>\n      <th>WindDir9am</th>\n      <th>WindDir3pm</th>\n      <th>...</th>\n      <th>Humidity9am</th>\n      <th>Humidity3pm</th>\n      <th>Pressure9am</th>\n      <th>Pressure3pm</th>\n      <th>Cloud9am</th>\n      <th>Cloud3pm</th>\n      <th>Temp9am</th>\n      <th>Temp3pm</th>\n      <th>RainToday</th>\n      <th>RainTomorrow</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2/1/2008</td>\n      <td>19.5</td>\n      <td>22.4</td>\n      <td>15.6</td>\n      <td>6.2</td>\n      <td>0.0</td>\n      <td>W</td>\n      <td>41</td>\n      <td>S</td>\n      <td>SSW</td>\n      <td>...</td>\n      <td>92</td>\n      <td>84</td>\n      <td>1017.6</td>\n      <td>1017.4</td>\n      <td>8</td>\n      <td>8</td>\n      <td>20.7</td>\n      <td>20.9</td>\n      <td>Yes</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2/2/2008</td>\n      <td>19.5</td>\n      <td>25.6</td>\n      <td>6.0</td>\n      <td>3.4</td>\n      <td>2.7</td>\n      <td>W</td>\n      <td>41</td>\n      <td>W</td>\n      <td>E</td>\n      <td>...</td>\n      <td>83</td>\n      <td>73</td>\n      <td>1017.9</td>\n      <td>1016.4</td>\n      <td>7</td>\n      <td>7</td>\n      <td>22.4</td>\n      <td>24.8</td>\n      <td>Yes</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2/3/2008</td>\n      <td>21.6</td>\n      <td>24.5</td>\n      <td>6.6</td>\n      <td>2.4</td>\n      <td>0.1</td>\n      <td>W</td>\n      <td>41</td>\n      <td>ESE</td>\n      <td>ESE</td>\n      <td>...</td>\n      <td>88</td>\n      <td>86</td>\n      <td>1016.7</td>\n      <td>1015.6</td>\n      <td>7</td>\n      <td>8</td>\n      <td>23.5</td>\n      <td>23.0</td>\n      <td>Yes</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2/4/2008</td>\n      <td>20.2</td>\n      <td>22.8</td>\n      <td>18.8</td>\n      <td>2.2</td>\n      <td>0.0</td>\n      <td>W</td>\n      <td>41</td>\n      <td>NNE</td>\n      <td>E</td>\n      <td>...</td>\n      <td>83</td>\n      <td>90</td>\n      <td>1014.2</td>\n      <td>1011.8</td>\n      <td>8</td>\n      <td>8</td>\n      <td>21.4</td>\n      <td>20.9</td>\n      <td>Yes</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2/5/2008</td>\n      <td>19.7</td>\n      <td>25.7</td>\n      <td>77.4</td>\n      <td>4.8</td>\n      <td>0.0</td>\n      <td>W</td>\n      <td>41</td>\n      <td>NNE</td>\n      <td>W</td>\n      <td>...</td>\n      <td>88</td>\n      <td>74</td>\n      <td>1008.3</td>\n      <td>1004.8</td>\n      <td>8</td>\n      <td>8</td>\n      <td>22.5</td>\n      <td>25.5</td>\n      <td>Yes</td>\n      <td>Yes</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 22 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": "### Data Preprocessing\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "#### One Hot Encoding\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "First, we need to perform one hot encoding to convert categorical variables to binary variables.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "df_sydney_processed = pd.get_dummies(data=df, columns=['RainToday', 'WindGustDir', 'WindDir9am', 'WindDir3pm'])\ndf_sydney_processed.head()",
      "metadata": {
        "trusted": true
      },
      "execution_count": 7,
      "outputs": [
        {
          "execution_count": 7,
          "output_type": "execute_result",
          "data": {
            "text/plain": "       Date  MinTemp  MaxTemp  Rainfall  Evaporation  Sunshine  WindGustSpeed  \\\n0  2/1/2008     19.5     22.4      15.6          6.2       0.0             41   \n1  2/2/2008     19.5     25.6       6.0          3.4       2.7             41   \n2  2/3/2008     21.6     24.5       6.6          2.4       0.1             41   \n3  2/4/2008     20.2     22.8      18.8          2.2       0.0             41   \n4  2/5/2008     19.7     25.7      77.4          4.8       0.0             41   \n\n   WindSpeed9am  WindSpeed3pm  Humidity9am  ...  WindDir3pm_NNW  \\\n0            17            20           92  ...               0   \n1             9            13           83  ...               0   \n2            17             2           88  ...               0   \n3            22            20           83  ...               0   \n4            11             6           88  ...               0   \n\n   WindDir3pm_NW  WindDir3pm_S  WindDir3pm_SE  WindDir3pm_SSE  WindDir3pm_SSW  \\\n0              0             0              0               0               1   \n1              0             0              0               0               0   \n2              0             0              0               0               0   \n3              0             0              0               0               0   \n4              0             0              0               0               0   \n\n   WindDir3pm_SW WindDir3pm_W  WindDir3pm_WNW  WindDir3pm_WSW  \n0              0            0               0               0  \n1              0            0               0               0  \n2              0            0               0               0  \n3              0            0               0               0  \n4              0            1               0               0  \n\n[5 rows x 68 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date</th>\n      <th>MinTemp</th>\n      <th>MaxTemp</th>\n      <th>Rainfall</th>\n      <th>Evaporation</th>\n      <th>Sunshine</th>\n      <th>WindGustSpeed</th>\n      <th>WindSpeed9am</th>\n      <th>WindSpeed3pm</th>\n      <th>Humidity9am</th>\n      <th>...</th>\n      <th>WindDir3pm_NNW</th>\n      <th>WindDir3pm_NW</th>\n      <th>WindDir3pm_S</th>\n      <th>WindDir3pm_SE</th>\n      <th>WindDir3pm_SSE</th>\n      <th>WindDir3pm_SSW</th>\n      <th>WindDir3pm_SW</th>\n      <th>WindDir3pm_W</th>\n      <th>WindDir3pm_WNW</th>\n      <th>WindDir3pm_WSW</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2/1/2008</td>\n      <td>19.5</td>\n      <td>22.4</td>\n      <td>15.6</td>\n      <td>6.2</td>\n      <td>0.0</td>\n      <td>41</td>\n      <td>17</td>\n      <td>20</td>\n      <td>92</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2/2/2008</td>\n      <td>19.5</td>\n      <td>25.6</td>\n      <td>6.0</td>\n      <td>3.4</td>\n      <td>2.7</td>\n      <td>41</td>\n      <td>9</td>\n      <td>13</td>\n      <td>83</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2/3/2008</td>\n      <td>21.6</td>\n      <td>24.5</td>\n      <td>6.6</td>\n      <td>2.4</td>\n      <td>0.1</td>\n      <td>41</td>\n      <td>17</td>\n      <td>2</td>\n      <td>88</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2/4/2008</td>\n      <td>20.2</td>\n      <td>22.8</td>\n      <td>18.8</td>\n      <td>2.2</td>\n      <td>0.0</td>\n      <td>41</td>\n      <td>22</td>\n      <td>20</td>\n      <td>83</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2/5/2008</td>\n      <td>19.7</td>\n      <td>25.7</td>\n      <td>77.4</td>\n      <td>4.8</td>\n      <td>0.0</td>\n      <td>41</td>\n      <td>11</td>\n      <td>6</td>\n      <td>88</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 68 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": "Next, we replace the values of the 'RainTomorrow' column changing them from a categorical column to a binary column. We do not use the `get_dummies` method because we would end up with two columns for 'RainTomorrow' and we do not want, since 'RainTomorrow' is our target.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "df_sydney_processed.replace(['No', 'Yes'], [0,1], inplace=True)",
      "metadata": {
        "trusted": true
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "df_sydney_processed.shape",
      "metadata": {
        "trusted": true
      },
      "execution_count": 10,
      "outputs": [
        {
          "execution_count": 10,
          "output_type": "execute_result",
          "data": {
            "text/plain": "(3271, 68)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": "df_sydney_processed.info()",
      "metadata": {
        "trusted": true
      },
      "execution_count": 11,
      "outputs": [
        {
          "name": "stdout",
          "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 3271 entries, 0 to 3270\nData columns (total 68 columns):\n #   Column           Non-Null Count  Dtype  \n---  ------           --------------  -----  \n 0   Date             3271 non-null   object \n 1   MinTemp          3271 non-null   float64\n 2   MaxTemp          3271 non-null   float64\n 3   Rainfall         3271 non-null   float64\n 4   Evaporation      3271 non-null   float64\n 5   Sunshine         3271 non-null   float64\n 6   WindGustSpeed    3271 non-null   int64  \n 7   WindSpeed9am     3271 non-null   int64  \n 8   WindSpeed3pm     3271 non-null   int64  \n 9   Humidity9am      3271 non-null   int64  \n 10  Humidity3pm      3271 non-null   int64  \n 11  Pressure9am      3271 non-null   float64\n 12  Pressure3pm      3271 non-null   float64\n 13  Cloud9am         3271 non-null   int64  \n 14  Cloud3pm         3271 non-null   int64  \n 15  Temp9am          3271 non-null   float64\n 16  Temp3pm          3271 non-null   float64\n 17  RainTomorrow     3271 non-null   int64  \n 18  RainToday_No     3271 non-null   uint8  \n 19  RainToday_Yes    3271 non-null   uint8  \n 20  WindGustDir_E    3271 non-null   uint8  \n 21  WindGustDir_ENE  3271 non-null   uint8  \n 22  WindGustDir_ESE  3271 non-null   uint8  \n 23  WindGustDir_N    3271 non-null   uint8  \n 24  WindGustDir_NE   3271 non-null   uint8  \n 25  WindGustDir_NNE  3271 non-null   uint8  \n 26  WindGustDir_NNW  3271 non-null   uint8  \n 27  WindGustDir_NW   3271 non-null   uint8  \n 28  WindGustDir_S    3271 non-null   uint8  \n 29  WindGustDir_SE   3271 non-null   uint8  \n 30  WindGustDir_SSE  3271 non-null   uint8  \n 31  WindGustDir_SSW  3271 non-null   uint8  \n 32  WindGustDir_SW   3271 non-null   uint8  \n 33  WindGustDir_W    3271 non-null   uint8  \n 34  WindGustDir_WNW  3271 non-null   uint8  \n 35  WindGustDir_WSW  3271 non-null   uint8  \n 36  WindDir9am_E     3271 non-null   uint8  \n 37  WindDir9am_ENE   3271 non-null   uint8  \n 38  WindDir9am_ESE   3271 non-null   uint8  \n 39  WindDir9am_N     3271 non-null   uint8  \n 40  WindDir9am_NE    3271 non-null   uint8  \n 41  WindDir9am_NNE   3271 non-null   uint8  \n 42  WindDir9am_NNW   3271 non-null   uint8  \n 43  WindDir9am_NW    3271 non-null   uint8  \n 44  WindDir9am_S     3271 non-null   uint8  \n 45  WindDir9am_SE    3271 non-null   uint8  \n 46  WindDir9am_SSE   3271 non-null   uint8  \n 47  WindDir9am_SSW   3271 non-null   uint8  \n 48  WindDir9am_SW    3271 non-null   uint8  \n 49  WindDir9am_W     3271 non-null   uint8  \n 50  WindDir9am_WNW   3271 non-null   uint8  \n 51  WindDir9am_WSW   3271 non-null   uint8  \n 52  WindDir3pm_E     3271 non-null   uint8  \n 53  WindDir3pm_ENE   3271 non-null   uint8  \n 54  WindDir3pm_ESE   3271 non-null   uint8  \n 55  WindDir3pm_N     3271 non-null   uint8  \n 56  WindDir3pm_NE    3271 non-null   uint8  \n 57  WindDir3pm_NNE   3271 non-null   uint8  \n 58  WindDir3pm_NNW   3271 non-null   uint8  \n 59  WindDir3pm_NW    3271 non-null   uint8  \n 60  WindDir3pm_S     3271 non-null   uint8  \n 61  WindDir3pm_SE    3271 non-null   uint8  \n 62  WindDir3pm_SSE   3271 non-null   uint8  \n 63  WindDir3pm_SSW   3271 non-null   uint8  \n 64  WindDir3pm_SW    3271 non-null   uint8  \n 65  WindDir3pm_W     3271 non-null   uint8  \n 66  WindDir3pm_WNW   3271 non-null   uint8  \n 67  WindDir3pm_WSW   3271 non-null   uint8  \ndtypes: float64(9), int64(8), object(1), uint8(50)\nmemory usage: 607.0+ KB\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": "### Training Data and Test Data\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Now, we set our 'features' or x values and our Y or target variable.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "df_sydney_processed.drop('Date',axis=1,inplace=True)",
      "metadata": {
        "trusted": true
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "df_sydney_processed = df_sydney_processed.astype(float)",
      "metadata": {
        "trusted": true
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "features = df_sydney_processed.drop(columns='RainTomorrow', axis=1)\nY = df_sydney_processed['RainTomorrow']",
      "metadata": {
        "trusted": true
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "#### Q1) Use the `train_test_split` function to split the `features` and `Y` dataframes with a `test_size` of `0.2` and the `random_state` set to `1`.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#Enter Your Code Below and Execute\nfrom sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(features, Y, test_size=.2, random_state=1)\nprint ('Train set:', x_train.shape,  y_train.shape)\nprint ('Test set:', x_test.shape,  y_test.shape)",
      "metadata": {
        "trusted": true
      },
      "execution_count": 16,
      "outputs": [
        {
          "name": "stdout",
          "text": "Train set: (2616, 66) (2616,)\nTest set: (655, 66) (655,)\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": "x_train, x_test, y_train, y_test = train_test_split(features, Y, test_size=.2, random_state=1)",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "### Logistic Regression\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "#### Q2) Create and train a LogisticRegression model called LR using the training data (`x_train`, `y_train`)\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#Enter Your Code Below and Execute\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix\nLR = LogisticRegression(solver='liblinear')\nLR.fit(x_train, y_train)",
      "metadata": {
        "trusted": true
      },
      "execution_count": 17,
      "outputs": [
        {
          "execution_count": 17,
          "output_type": "execute_result",
          "data": {
            "text/plain": "LogisticRegression(solver='liblinear')"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": "LR = LogisticRegression(solver='liblinear')\nLR.fit(x_train, y_train)",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "#### Q3) Now, use the `predict` method on the testing data (`x_test`) and save it to the array `predictions`.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#Enter Your Code Below and Execute\npredictions = LR.predict(x_test)\npredictions",
      "metadata": {
        "trusted": true
      },
      "execution_count": 18,
      "outputs": [
        {
          "execution_count": 18,
          "output_type": "execute_result",
          "data": {
            "text/plain": "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1.,\n       0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n       1., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n       0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1.,\n       0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n       0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0.,\n       0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n       0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 1.,\n       0., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 1., 0.,\n       0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0.,\n       0., 1., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n       1., 0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0.,\n       0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 1.,\n       0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0.,\n       1., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1.,\n       1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 1., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n       1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.,\n       0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1.,\n       1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n       0., 1., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.,\n       1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 1.,\n       0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n       0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0.,\n       0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n       0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n       0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0.,\n       0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0.,\n       0., 0., 1., 0., 1., 0., 0., 0., 1.])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": "predictions = LR.predict(x_test)",
      "metadata": {
        "trusted": true
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "#### Q4) Using the `predictions` and the `y_test` dataframe calculate the value for each metric using the appropriate function.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#Enter Your Code Below and Execute\n#from sklearn.metrics import jaccard_score\nLR_Accuracy_Score = metrics.accuracy_score(y_test, predictions)\nLR_JaccardIndex = metrics.jaccard_score(y_test, predictions)\nLR_F1_Score = metrics.f1_score(y_test, predictions)\nLR_Log_Loss = metrics.log_loss(y_test, predictions)\nprint('Accuracy Score: ', LR_Accuracy_Score)\nprint('Jaccard Index: ', LR_JaccardIndex)\nprint('F1 Score: ', LR_F1_Score)\nprint('Log Loss: ', LR_Log_Loss)",
      "metadata": {
        "trusted": true
      },
      "execution_count": 22,
      "outputs": [
        {
          "name": "stdout",
          "text": "Accuracy Score:  0.8351145038167939\nJaccard Index:  0.5045871559633027\nF1 Score:  0.6707317073170731\nLog Loss:  5.69498723077533\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": "LR_Accuracy_Score = metrics.accuracy_score(y_test, predictions)\nLR_JaccardIndex = metrics.jaccard_score(y_test, predictions)\nLR_F1_Score = metrics.f1_score(y_test, predictions)\nLR_Log_Loss = metrics.log_loss(y_test, predictions)",
      "metadata": {
        "trusted": true
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "### KNN\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "#### Q5) Create and train a KNN model called KNN using the training data (`x_train`, `y_train`) with the `n_neighbors` parameter set to `4`.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#Enter Your Code Below and Execute\nfrom sklearn.neighbors import KNeighborsClassifier\nKNN = KNeighborsClassifier(n_neighbors=4)\nKNN.fit(x_train, y_train)",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "KNN = KNeighborsClassifier(n_neighbors=4)\nKNN.fit(x_train, y_train)",
      "metadata": {
        "trusted": true
      },
      "execution_count": 23,
      "outputs": [
        {
          "execution_count": 23,
          "output_type": "execute_result",
          "data": {
            "text/plain": "KNeighborsClassifier(n_neighbors=4)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": "#### Q6) Now use the `predict` method on the testing data (`x_test`) and save it to the array `predictions`.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#Enter Your Code Below and Execute\npredictions = KNN.predict(x_test)\npredictions",
      "metadata": {
        "trusted": true
      },
      "execution_count": 24,
      "outputs": [
        {
          "execution_count": 24,
          "output_type": "execute_result",
          "data": {
            "text/plain": "array([0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1.,\n       0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n       0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1.,\n       0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n       0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 1.,\n       0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0.,\n       0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0.,\n       0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n       0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1.,\n       0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0.,\n       0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.,\n       0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n       1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n       0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0.,\n       1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 1.,\n       0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n       0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n       0., 0., 1., 0., 1., 0., 0., 0., 1.])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": "predictions = KNN.predict(x_test)\npredictions",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "#### Q7) Using the `predictions` and the `y_test` dataframe calculate the value for each metric using the appropriate function.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#Enter Your Code Below and Execute\nKNN_Accuracy_Score = metrics.accuracy_score(predictions, y_test)\nKNN_JaccardIndex = metrics.jaccard_score(predictions, y_test)\nKNN_F1_Score = metrics.f1_score(predictions, y_test)\nprint('Accuracy Score: ', KNN_Accuracy_Score)\nprint('Jaccard Index: ', KNN_JaccardIndex)\nprint('F1 Score: ', KNN_F1_Score)",
      "metadata": {
        "trusted": true
      },
      "execution_count": 26,
      "outputs": [
        {
          "name": "stdout",
          "text": "Accuracy Score:  0.8122137404580153\nJaccard Index:  0.39408866995073893\nF1 Score:  0.5653710247349824\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": "KNN_Accuracy_Score = metrics.accuracy_score(predictions, y_test)\nKNN_JaccardIndex = metrics.jaccard_score(predictions, y_test)\nKNN_F1_Score = metrics.f1_score(predictions, y_test)",
      "metadata": {
        "trusted": true
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "### SVM\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "#### Q8) Create and train a SVM model called SVM using the training data (`x_train`, `y_train`).\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#Enter Your Code Below and Execute\nfrom sklearn import svm\nSVM = svm.SVC()\nSVM.fit(x_train, y_train)",
      "metadata": {
        "trusted": true
      },
      "execution_count": 27,
      "outputs": [
        {
          "execution_count": 27,
          "output_type": "execute_result",
          "data": {
            "text/plain": "SVC()"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": "SVM = svm.SVC()\nSVM.fit(x_train, y_train)",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "#### Q9) Now use the `predict` method on the testing data (`x_test`) and save it to the array `predictions`.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#Enter Your Code Below and Execute\npredictions = SVM.predict(x_test)\npredictions",
      "metadata": {
        "trusted": true
      },
      "execution_count": 28,
      "outputs": [
        {
          "execution_count": 28,
          "output_type": "execute_result",
          "data": {
            "text/plain": "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0.])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": "predictions = SVM.predict(x_test)\npredictions",
      "metadata": {
        "trusted": true
      },
      "execution_count": 29,
      "outputs": [
        {
          "execution_count": 29,
          "output_type": "execute_result",
          "data": {
            "text/plain": "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0.])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": "#### Q10) Using the `predictions` and the `y_test` dataframe calculate the value for each metric using the appropriate function.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "SVM_Accuracy_Score = metrics.accuracy_score(predictions, y_test)\nSVM_JaccardIndex = metrics.jaccard_score(predictions, y_test)\nSVM_F1_Score = metrics.f1_score(predictions, y_test)\nprint('Accuracy Score: ', SVM_Accuracy_Score)\nprint('Jaccard Index: ', SVM_JaccardIndex)\nprint('F1 Score: ', SVM_F1_Score)",
      "metadata": {
        "trusted": true
      },
      "execution_count": 30,
      "outputs": [
        {
          "name": "stdout",
          "text": "Accuracy Score:  0.7221374045801526\nJaccard Index:  0.0\nF1 Score:  0.0\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": "## Decision Tree\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "#### Q11) Create and train a Decision Tree model called Tree using the training data (`x_train`, `y_train`).\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#Enter Your Code Here and Execute\nfrom sklearn.tree import DecisionTreeClassifier\nTree = DecisionTreeClassifier()\nTree.fit(x_train, y_train)",
      "metadata": {
        "trusted": true
      },
      "execution_count": 31,
      "outputs": [
        {
          "execution_count": 31,
          "output_type": "execute_result",
          "data": {
            "text/plain": "DecisionTreeClassifier()"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": "Tree = DecisionTreeClassifier()\nTree.fit(x_train, y_train)",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "#### Q12) Now use the `predict` method on the testing data (`x_test`) and save it to the array `predictions`.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#Enter Your Code Here and Execute\npredictions = Tree.predict(x_test)\npredictions",
      "metadata": {
        "trusted": true
      },
      "execution_count": 32,
      "outputs": [
        {
          "execution_count": 32,
          "output_type": "execute_result",
          "data": {
            "text/plain": "array([0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n       0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0.,\n       0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0.,\n       0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n       0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1.,\n       0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1.,\n       0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0.,\n       0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.,\n       0., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 0., 1.,\n       0., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1., 0., 0., 0., 1., 0., 0.,\n       0., 0., 0., 1., 1., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 0.,\n       0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0., 1., 0.,\n       0., 1., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n       1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0.,\n       0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 1.,\n       0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0.,\n       0., 1., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0.,\n       1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0.,\n       1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 1., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0.,\n       1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.,\n       0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.,\n       0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1.,\n       1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 1., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1.,\n       0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n       0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n       0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n       0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0.,\n       0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0.,\n       0., 1., 1., 0., 1., 1., 0., 0., 1.])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": "predictions = Tree.predict(x_test)",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "#### Q12) Using the `predictions` and the `y_test` dataframe calculate the value for each metric using the appropriate function.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#Enter Your Code Here and Execute\nTree_Accuracy_Score = metrics.accuracy_score(predictions, y_test)\nTree_JaccardIndex = metrics.jaccard_score(predictions, y_test)\nTree_F1_Score = metrics.f1_score(predictions, y_test)\nprint('Accuracy Score: ', Tree_Accuracy_Score)\nprint('Jaccard Index: ', Tree_JaccardIndex)\nprint('F1 Score: ', Tree_F1_Score)",
      "metadata": {
        "trusted": true
      },
      "execution_count": 33,
      "outputs": [
        {
          "name": "stdout",
          "text": "Accuracy Score:  0.7801526717557252\nJaccard Index:  0.4146341463414634\nF1 Score:  0.5862068965517242\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": "Tree_Accuracy_Score = metrics.accuracy_score(predictions, y_test)\nTree_JaccardIndex = metrics.jaccard_score(predictions, y_test)\nTree_F1_Score = metrics.f1_score(predictions, y_test)",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "### Report\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "#### Q14) Show the Accuracy,Jaccard Index,F1-Score and LogLoss in a tabular format using data frame for all of the above models.\n\n\\*LogLoss is only for Logistic Regression Model\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "Report = pd.DataFrame({'Algorithm' : ['LogisticRegression', 'KNN', 'SVM', 'Decision Tree']})\n\n\nReport['Accuracy'] = [LR_Accuracy_Score, KNN_Accuracy_Score, SVM_Accuracy_Score, Tree_Accuracy_Score]\nReport['Jaccard'] = [LR_JaccardIndex, KNN_JaccardIndex, SVM_JaccardIndex, Tree_JaccardIndex]\nReport['F1-Score'] = [LR_F1_Score, KNN_F1_Score, SVM_F1_Score, Tree_F1_Score]\nReport['LogLoss'] = [ LR_Log_Loss, 'N/A', 'N/A', 'N/A']\nReport",
      "metadata": {
        "trusted": true
      },
      "execution_count": 34,
      "outputs": [
        {
          "execution_count": 34,
          "output_type": "execute_result",
          "data": {
            "text/plain": "            Algorithm  Accuracy   Jaccard  F1-Score   LogLoss\n0  LogisticRegression  0.835115  0.504587  0.670732  5.694987\n1                 KNN  0.812214  0.394089  0.565371       N/A\n2                 SVM  0.722137  0.000000  0.000000       N/A\n3       Decision Tree  0.780153  0.414634  0.586207       N/A",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Algorithm</th>\n      <th>Accuracy</th>\n      <th>Jaccard</th>\n      <th>F1-Score</th>\n      <th>LogLoss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>LogisticRegression</td>\n      <td>0.835115</td>\n      <td>0.504587</td>\n      <td>0.670732</td>\n      <td>5.694987</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>KNN</td>\n      <td>0.812214</td>\n      <td>0.394089</td>\n      <td>0.565371</td>\n      <td>N/A</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>SVM</td>\n      <td>0.722137</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>N/A</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Decision Tree</td>\n      <td>0.780153</td>\n      <td>0.414634</td>\n      <td>0.586207</td>\n      <td>N/A</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": "#### Q15) Use the `train_test_split` function to split the `features` and `Y` dataframes with a `test_size` of `0.2` and the `random_state` set to `10`.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#Enter Your Code Here and Execute\nx_train, x_test, y_train, y_test = train_test_split(features, Y, test_size=.2, random_state=10)",
      "metadata": {
        "trusted": true
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "x_train, x_test, y_train, y_test = train_test_split(features, Y, test_size=.2, random_state=1)",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "#### Q16) Create and train a Linear Regression model called LinearReg using the training data (`x_train`, `y_train`).\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#Enter Your Code Here and Execute\nx_train, x_test, y_train, y_test = train_test_split(features, Y, test_size=.2, random_state=1)\nLinearReg = LinearRegression()\nLinearReg.fit(x_train, y_train)\nprint ('Coefficients: ', LinearReg.coef_)\nprint ('Intercept: ', LinearReg.intercept_)",
      "metadata": {
        "trusted": true
      },
      "execution_count": 36,
      "outputs": [
        {
          "name": "stdout",
          "text": "Coefficients:  [-2.32244507e-02  6.49270040e-03  1.89714504e-03  4.02915384e-03\n -3.69702175e-02  4.47864215e-03  1.47529242e-03 -3.55524000e-04\n  1.81306195e-03  7.99919146e-03  6.12900473e-03 -9.31746873e-03\n -1.69018898e-02  1.50022041e-02  1.68138084e-02  1.30146390e-03\n  6.41581836e+09  6.41581836e+09 -1.98497297e+10 -1.98497297e+10\n -1.98497297e+10 -1.98497297e+10 -1.98497297e+10 -1.98497297e+10\n -1.98497297e+10 -1.98497297e+10 -1.98497297e+10 -1.98497297e+10\n -1.98497297e+10 -1.98497297e+10 -1.98497297e+10 -1.98497297e+10\n -1.98497297e+10 -1.98497297e+10  4.43619688e+09  4.43619688e+09\n  4.43619688e+09  4.43619688e+09  4.43619688e+09  4.43619688e+09\n  4.43619688e+09  4.43619688e+09  4.43619688e+09  4.43619688e+09\n  4.43619688e+09  4.43619688e+09  4.43619688e+09  4.43619688e+09\n  4.43619688e+09  4.43619688e+09  2.36173959e+09  2.36173959e+09\n  2.36173959e+09  2.36173959e+09  2.36173959e+09  2.36173959e+09\n  2.36173959e+09  2.36173959e+09  2.36173959e+09  2.36173959e+09\n  2.36173959e+09  2.36173959e+09  2.36173959e+09  2.36173959e+09\n  2.36173959e+09  2.36173959e+09]\nIntercept:  6635974837.934501\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": "LinearReg = LinearRegression()\nLinearReg.fit(x_train, y_train)",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "#### Q17) Now use the `predict` method on the testing data (`x_test`) and save it to the array `predictions`.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#Enter Your Code Here and Execute\npredictions = LinearReg.predict(x_test)\npredictions",
      "metadata": {
        "trusted": true
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "predictions = LinearReg.predict(x_test)",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "#### Q18) Using the `predictions` and the `y_test` dataframe calculate the value for each metric using the appropriate function.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#Enter Your Code Here and Execute\nLinearRegression_MAE = metrics.mean_absolute_error(predictions, y_test)\nLinearRegression_MSE = metrics.mean_squared_error(predictions, y_test)\nLinearRegression_R2 = metrics.r2_score(predictions, y_test)\nprint('Linear Regression MAE: ', LinearRegression_MAE)\nprint('Linear Regression MSE: ', LinearRegression_MSE)\nprint('Linear Regression R2: ', LinearRegression_R2)",
      "metadata": {
        "trusted": true
      },
      "execution_count": 39,
      "outputs": [
        {
          "name": "stdout",
          "text": "Linear Regression MAE:  0.2655638308925483\nLinear Regression MSE:  0.12314579924269442\nLinear Regression R2:  -0.43790032006393\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": "LinearRegression_MAE = metrics.mean_absolute_error(predictions, y_test)\nLinearRegression_MSE = metrics.mean_squared_error(predictions, y_test)\nLinearRegression_R2 = metrics.r2_score(predictions, y_test)",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "#### Q19) Show the MAE, MSE, and R2 in a tabular format using data frame for the linear model.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#Enter Your Code Here and Execute\nReport = pd.DataFrame({'Algorithm' : ['LinearRegression']})\n\n\nReport['MAE'] = [LinearRegression_MAE]\nReport['MSE'] = [LinearRegression_MSE]\nReport['R2'] = [LinearRegression_R2]\n\nReport",
      "metadata": {
        "trusted": true
      },
      "execution_count": 40,
      "outputs": [
        {
          "execution_count": 40,
          "output_type": "execute_result",
          "data": {
            "text/plain": "          Algorithm       MAE       MSE      R2\n0  LinearRegression  0.265564  0.123146 -0.4379",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Algorithm</th>\n      <th>MAE</th>\n      <th>MSE</th>\n      <th>R2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>LinearRegression</td>\n      <td>0.265564</td>\n      <td>0.123146</td>\n      <td>-0.4379</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": "Report = pd.DataFrame({'Algorithm' : ['LinearRegression']})\n\n\nReport['MAE'] = [LinearRegression_MAE]\nReport['MSE'] = [LinearRegression_MSE]\nReport['R2'] = [LinearRegression_R2]\n\nReport",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "<h2 id=\"Section_5\">  How to submit </h2>\n\n<p>Once you complete your notebook you will have to share it. You can download the notebook by navigating to \"File\" and clicking on \"Download\" button.\n\n<p>This will save the (.ipynb) file on your computer. Once saved, you can upload this file in the \"My Submission\" tab, of the \"Peer-graded Assignment\" section.  \n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "<h2>About the Authors:</h2> \n\n<a href=\"https://www.linkedin.com/in/joseph-s-50398b136/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkML0101ENSkillsNetwork20718538-2022-01-01\">Joseph Santarcangelo</a> has a PhD in Electrical Engineering, his research focused on using machine learning, signal processing, and computer vision to determine how videos impact human cognition. Joseph has been working for IBM since he completed his PhD.\n\n### Other Contributors\n\n<a href=\"https://www.linkedin.com/in/birlahimanshu/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkML0101ENSkillsNetwork20718538-2022-01-01\" target=\"_blank\">Himanshu Birla</a>\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Change Log\n\n| Date (YYYY-MM-DD) | Version | Changed By    | Change Description          |\n| ----------------- | ------- | ------------- | --------------------------- |\n| 2020-08-27        | 1.0     | Malika Singla | Added lab to GitLab         |\n| 2022-06-22        | 2.0     | Lana K.       | Deleted GridSearch and Mock |\n| <hr>              |         |               |                             |\n\n## <h3 align=\"center\"> © IBM Corporation 2020. All rights reserved. <h3/>\n",
      "metadata": {}
    }
  ]
}